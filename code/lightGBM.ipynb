{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_PATH = os.getcwd()\n",
    "BASE_PATH =  os.path.dirname(CODE_PATH) + '/'\n",
    "print(BASE_PATH)\n",
    "DATA_PATH = BASE_PATH + 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(DATA_PATH + 'train_df.csv')\n",
    "test_df = pd.read_csv(DATA_PATH + 'test_df.csv')\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df.iloc[:, :11]\n",
    "y = train_df.iloc[:, 11:12]\n",
    "X.head(1)\n",
    "# y.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBMで学習\n",
    "from   sklearn.metrics         import accuracy_score, roc_auc_score\n",
    "from   sklearn.model_selection import KFold\n",
    "import wandb\n",
    "from wandb.lightgbm import wandb_callback, log_summary\n",
    "import lightgbm as lgb\n",
    "import numpy    as np\n",
    "import optuna\n",
    "# 警告を非表示\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "#wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# パラメータ\n",
    "FOLD             = 5              # 交差検証の分ける回数\n",
    "NUM_ROUND        = 30000          # 学習ステップ数\n",
    "VERBOSE_EVAL     = 5000           # 学習結果の表示ステップ数\n",
    "SEED             = 42             # ランダム値のシード（再現性を持たせるため）\n",
    "# categorical_list = ['Gender_enc'] # カテゴリ変数\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingVerboseCallback:\n",
    "    def __init__(self, stopping_rounds, verbose=True):\n",
    "        self.stopping_rounds = stopping_rounds\n",
    "        self.verbose = verbose\n",
    "        self.best_score = float('inf')\n",
    "        self.best_iteration = None\n",
    "        self.counter = 0\n",
    "        \n",
    "    def __call__(self, env):\n",
    "        # Retrieve the current evaluation result\n",
    "        current_score = env.evaluation_result_list[-1][2]\n",
    "        \n",
    "        # Update the best score and iteration if current score is better\n",
    "        if current_score < self.best_score:\n",
    "            self.best_score = current_score\n",
    "            self.best_iteration = env.iteration\n",
    "            self.counter = 0\n",
    "        else:\n",
    "            self.counter += 1\n",
    "        \n",
    "        # Print the evaluation result (mimic verbose_eval)\n",
    "        if self.verbose:\n",
    "            print(f'[{env.iteration}] {env.evaluation_result_list[-1][0]}: {env.evaluation_result_list[-1][1]}: {current_score}')\n",
    "        \n",
    "        # Stop training if the stopping criterion is met\n",
    "        if self.counter >= self.stopping_rounds:\n",
    "            env.model.stop_training = True\n",
    "            print(f'Early stopping, best iteration is: {self.best_iteration}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_accuracy_for_lgbm(\n",
    "    preds: np.ndarray, data: lgb.Dataset, threshold: float=0.5,\n",
    "    ):\n",
    "    \"\"\"Calculate Binary Accuracy\"\"\"\n",
    "    label = data.get_label()\n",
    "    weight = data.get_weight()\n",
    "    pred_label = (preds > threshold).astype(int)\n",
    "    acc = np.average(label == pred_label, weights=weight)\n",
    "    # # eval_name, eval_result, is_higher_better\n",
    "    return 'my_bin_acc', acc, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # LightGBMパラメータチューニング（Optunaで探索）\n",
    "    params = {\n",
    "      'objective'       : 'binary',\n",
    "      'boosting_type'   : trial.suggest_categorical('boosting_type', ['gbdt', 'dart', 'goss']),  # default = gbdt\n",
    "      'num_leaves'      : trial.suggest_int('num_leaves', 10, 100),                             # default = 31\n",
    "      'max_depth'       : -1,      # default = -1(上限なし)\n",
    "      'learning_rate'   : trial.suggest_loguniform('learning_rate', 1e-8, 1.0),                  # default = 0.1\n",
    "      'feature_fraction': 0.8,     # default = 1.0\n",
    "      'bagging_freq'    : 0,       # default = 0\n",
    "      'random_state'    : SEED,    # default = None\n",
    "      'metric'          : trial.suggest_categorical('metrics', ['binary_logloss', 'rmse', 'auc']),  # default = 'binary_logloss',\n",
    "      #'device_type': 'cuda',  # Use GPU\n",
    "      # 'gpu_platform_id': 0,  # Platform ID, change if necessary\n",
    "      # 'gpu_device_id': 0,  # Device ID, change if necessary\n",
    "    }\n",
    "\n",
    "    valid_auc    = []\n",
    "    valid_acc    = []\n",
    "    models       = []\n",
    "    result_data  = {}\n",
    "\n",
    "    # kFold交差検定で決定係数を算出し、各セットの平均値を返す\n",
    "    kf = KFold(n_splits=FOLD, shuffle=True, random_state=42)\n",
    "    for fold, (train_indices, valid_indices) in enumerate(kf.split(X)):\n",
    "      # 指定したindexで学習・評価データを分ける\n",
    "      X_train, X_valid = X.iloc[train_indices], X.iloc[valid_indices] \n",
    "      y_train, y_valid = y.iloc[train_indices], y.iloc[valid_indices] \n",
    "\n",
    "      train_data = lgb.Dataset(X_train, y_train) \n",
    "      valid_data = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "      early_stopping_verbose_callback = EarlyStoppingVerboseCallback(stopping_rounds=10)\n",
    "      model = lgb.train(\n",
    "          params = params,\n",
    "          train_set             = train_data,\n",
    "          valid_sets            = [train_data, valid_data],\n",
    "          # categorical_feature   = categorical_list,         # カテゴリ値のカラムを指定(やらんでも動く)\n",
    "          num_boost_round       = NUM_ROUND,\n",
    "          callbacks=[early_stopping_verbose_callback, lgb.log_evaluation(1)],\n",
    "          feval                 = binary_accuracy_for_lgbm,\n",
    "      )\n",
    "\n",
    "      # 学習したモデルでバリデーションデータを予測\n",
    "      y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "      # aucを計算（本問題の運営側 評価方法）\n",
    "      auc = roc_auc_score(y_valid.to_numpy().squeeze(), y_valid_pred) # 引数：正解データ & 予測データ\n",
    "      valid_auc.append(auc)\n",
    "\n",
    "      # 正解率を計算\n",
    "      acc = accuracy_score(y_valid.to_numpy().squeeze(),np.round(y_valid_pred)) # 引数：正解データ & 予測データ(四捨五入（銀行丸めになっている点は注意)）\n",
    "      valid_acc.append(acc)\n",
    "\n",
    "    # 交差検証の正解率の平均 accを最大化\n",
    "    cv_acc = np.mean(valid_acc)\n",
    "    cv_auc = np.mean(valid_auc)\n",
    "    print('Accuracy: {}, auc: {}'.format(cv_acc, cv_auc))\n",
    "    return cv_acc\n",
    "\n",
    "# Optunaでハイパーパラメータ探索\n",
    "study = optuna.create_study(direction='maximize') # 今回は正解率（Accuracy）を最大化（本当はAUC最大化の方が良い）\n",
    "study.optimize(objective, n_trials=10)            # 試行回数10回"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optunaで探索したベストハイパラでLightGBMを再学習\n",
    "params = {\n",
    "    'objective'       : 'binary',\n",
    "    'boosting_type'   : study.best_params['boosting_type'], # Optunaで探索した値を指定\n",
    "    'num_leaves'      : study.best_params['num_leaves'],    # Optunaで探索した値を指定\n",
    "    'max_depth'       : -1,                                 # default = -1(上限なし)\n",
    "    'learning_rate   ': study.best_params['learning_rate'], # Optunaで探索した値を指定\n",
    "    'feature_fraction': 0.8,                                # default = 1.0\n",
    "    'bagging_freq'    : 1,                                  # default = 0\n",
    "    'random_state'    : 0,                                  # default = None\n",
    "    'metric'          : study.best_params['metrics'],       # Optunaで探索した値を指定\n",
    "    'seed'            : SEED\n",
    "}\n",
    "valid_scores = []\n",
    "valid_acc    = []\n",
    "models       = []\n",
    "result_data  = {}\n",
    "# kFold交差検定で決定係数を算出し、各セットの平均値を返す\n",
    "kf = KFold(n_splits=FOLD, shuffle=True, random_state=42)\n",
    "for fold, (train_indices, valid_indices) in enumerate(kf.split(X)):\n",
    "    # 指定したindexで学習・評価データを分ける\n",
    "    X_train, X_valid = X.iloc[train_indices], X.iloc[valid_indices] \n",
    "    y_train, y_valid = y.iloc[train_indices], y.iloc[valid_indices] \n",
    "\n",
    "    train_data = lgb.Dataset(X_train, y_train) \n",
    "    valid_data = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params = params,\n",
    "        train_set             = train_data,\n",
    "        valid_sets            = [train_data, valid_data],\n",
    "        #categorical_feature   = categorical_list,         # カテゴリ値のカラムを指定(やらんでも動く)\n",
    "        num_boost_round       = NUM_ROUND,\n",
    "        callbacks             =[lgb.early_stopping( stopping_rounds=10, \n",
    "                                                    verbose=True), # early_stopping用コールバック関数\n",
    "                                lgb.log_evaluation(VERBOSE_EVAL),\n",
    "                                #wandb_callback()\n",
    "                                ], # コマンドライン出力用コールバック関数\n",
    "        feval                 = binary_accuracy_for_lgbm, # 評価用関数\n",
    "    )\n",
    "\n",
    "    # 学習したモデルでバリデーションデータを予測\n",
    "    y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "    # aucを計算（本問題の運営側 評価方法）\n",
    "    auc = roc_auc_score(y_valid.to_numpy().squeeze(), y_valid_pred) # 引数：正解データ & 予測データ\n",
    "    valid_auc.append(auc)\n",
    "\n",
    "    # 正解率を計算\n",
    "    acc = accuracy_score(y_valid.to_numpy().squeeze(),np.round(y_valid_pred)) # 引数：正解データ & 予測データ(四捨五入（銀行丸めになっている点は注意)）\n",
    "    valid_acc.append(acc)\n",
    "    print('fold {} Accuracy:{}, auc:{}'.format(fold, acc, auc))\n",
    "\n",
    "    # モデルを保存\n",
    "    models.append(model)\n",
    "\n",
    "# 交差検証の正解率の平均\n",
    "cv_acc = np.mean(valid_acc)\n",
    "cv_auc = np.mean(valid_auc)\n",
    "print('Accuracy: {}, auc: {}'.format(cv_acc, cv_auc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kfoldで学習したモデルすべてで予測\n",
    "test_y_preds = []\n",
    "for model in models:\n",
    "  test_y_pred = model.predict(test_df)\n",
    "  test_y_preds.append(test_y_pred)\n",
    "\n",
    "test_prediction = np.mean(test_y_preds, axis=0)\n",
    "\n",
    "binary_prediction = (test_prediction >= 0.5).astype(int)\n",
    "binary_pred_df = pd.DataFrame(binary_prediction)\n",
    "binary_pred_df.to_csv('./binary_submit.csv', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train():\n",
    "#     with wandb.init(job_type=\"sweep\") as run:\n",
    "#         params = {\n",
    "#             'objective'              : 'binary',\n",
    "#             'boosting_type'          : wandb.config.boosting_type,\n",
    "#             'num_leaves'             : wandb.config.num_leaves,\n",
    "#             'max_depth'              : wandb.config.max_depth,\n",
    "#             'learning_rate'          : wandb.config.learning_rate,\n",
    "#             'feature_fraction'       : wandb.config.feature_fraction,\n",
    "#             # 'bagging_fraction'       : wandb.config.bagging_fraction,\n",
    "#             # 'bagging_freq'           : wandb.config.bagging_freq,\n",
    "#             # 'lambda_l1'              : wandb.config.lambda_l1,\n",
    "#             # 'lambda_l2'              : wandb.config.lambda_l2,\n",
    "#             # 'min_data_in_leaf'       : wandb.config.min_data_in_leaf,\n",
    "#             # 'min_sum_hessian_in_leaf': wandb.config.min_sum_hessian_in_leaf,\n",
    "#             # 'cat_smooth'             : wandb.config.cat_smooth,\n",
    "#             'random_state'           : SEED,\n",
    "#             'metric'                 : wandb.config.metric,\n",
    "#             'verbose'                : -1  # Avoid warnings of `No further splits with positive gain, best gain: -inf`\n",
    "#         }\n",
    "#         # kFold交差検定で決定係数を算出し、各セットの平均値を返す\n",
    "#         kf = KFold(n_splits=FOLD, shuffle=True, random_state=42)\n",
    "#         for fold, (train_indices, valid_indices) in enumerate(kf.split(X)):\n",
    "#             # 指定したindexで学習・評価データを分ける\n",
    "#             X_train, X_valid = X.iloc[train_indices], X.iloc[valid_indices] \n",
    "#             y_train, y_valid = y.iloc[train_indices], y.iloc[valid_indices] \n",
    "\n",
    "#             train_data = lgb.Dataset(X_train, y_train) \n",
    "#             valid_data = lgb.Dataset(X_valid, y_valid)\n",
    "\n",
    "#             model = lgb.train(\n",
    "#                 params = params,\n",
    "#                 train_set             = train_data,\n",
    "#                 valid_sets            = [train_data, valid_data],\n",
    "#                 #categorical_feature   = categorical_list,         # カテゴリ値のカラムを指定(やらんでも動く)\n",
    "#                 num_boost_round       = NUM_ROUND,\n",
    "#                 callbacks             =[lgb.early_stopping( stopping_rounds=10, \n",
    "#                                                             verbose=True), # early_stopping用コールバック関数\n",
    "#                                         lgb.log_evaluation(VERBOSE_EVAL),\n",
    "#                                         wandb_callback()\n",
    "#                                         ], # コマンドライン出力用コールバック関数\n",
    "#                 feval                 = binary_accuracy_for_lgbm, # 評価用関数\n",
    "#             )\n",
    "\n",
    "#             # 学習したモデルでバリデーションデータを予測\n",
    "#             y_valid_pred = model.predict(X_valid)\n",
    "\n",
    "#             # aucを計算（本問題の運営側 評価方法）\n",
    "#             auc = roc_auc_score(y_valid.to_numpy().squeeze(), y_valid_pred) # 引数：正解データ & 予測データ\n",
    "#             valid_auc.append(auc)\n",
    "\n",
    "#             # 正解率を計算\n",
    "#             acc = accuracy_score(y_valid.to_numpy().squeeze(),np.round(y_valid_pred)) # 引数：正解データ & 予測データ(四捨五入（銀行丸めになっている点は注意)）\n",
    "#             valid_acc.append(acc)\n",
    "\n",
    "#             ## 交差検証の正解率の平均\n",
    "#             run.summary[\"cv_valid_acc\"] = np.mean(valid_acc)\n",
    "#             run.summary[\"cv_valid_auc\"] = np.mean(valid_auc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "file = CODE_PATH\n",
    "with open('lightGBMparams.yaml', 'r') as file:\n",
    "    sweep_config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sweep_id = wandb.sweep(sweep_config, project=\"signate-LiverDisease\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sweep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.agent(sweep_id, function=train\n",
    "            #, count=10\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
